# ML examples for natural language inference (NLI)
## Datasets
* [The Stanford Natural Language Inference (SNLI) Corpus](https://nlp.stanford.edu/projects/snli/)
    * Access: https://huggingface.co/datasets/snli
* [GLUE Benchmark](https://gluebenchmark.com/)
    * Access: https://huggingface.co/datasets/glue:
    * Relevant subsets:
        * MNLI
        * QNLI
        * RTE

## ToDo
* Try active learning using BaaL and compare with finetuning

## References
### NLI
* https://d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html
* https://nlp.stanford.edu/manning/talks/SIGIR2016-Deep-Learning-NLI.pdf
* https://towardsdatascience.com/natural-language-inference-an-overview-57c0eecf6517
* https://ai.facebook.com/research/publications/adversarial-nli-a-new-benchmark-for-natural-language-understanding/
* https://microsoft.github.io/nlp-recipes/examples/entailment/
* [Semantics-aware BERT for Language Understanding](https://arxiv.org/pdf/1909.02209.pdf)
### Automated Short Answer Grading (ASAG)
* [Survey on Automated Short Answer Grading with Deep Learning: from Word Embeddings to Transformers](https://arxiv.org/pdf/2204.03503.pdf)
* [Investigating Transformers for Automatic Short Answer Grading](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7334688/pdf/978-3-030-52240-7_Chapter_8.pdf)
* [SemEval-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge](https://aclanthology.org/S13-2045.pdf)
### Active Learning
https://github.com/thierry-wendling/ai-references/blob/main/README.md#active-learning