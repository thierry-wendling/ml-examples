{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTE (Recognizing Textual Entailment) with transformers\n",
    "## Using a pretrained transformer fine-tuned on MNLI for fine-tuning on SNLI\n",
    "Inspired by Keras code example [Semantic Similarity with BERT](https://keras.io/examples/nlp/semantic_similarity_with_bert/)\n",
    "\n",
    "Executed on AWS SageMaker `ml.g4dn.2xlarge` GPU instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch] accelerate datasets wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, \n",
    "    AdamW, get_scheduler,\n",
    "#     EarlyStoppingCallback,\n",
    "#     Trainer, TrainingArguments\n",
    "    )\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 3\n",
    "MAX_LENGTH = 128\n",
    "HUB_MODEL_CHECKPOINT = 'bert-base-uncased'\n",
    "MODEL_NAME = HUB_MODEL_CHECKPOINT.split(\"/\")[-1]\n",
    "PROJECT_NAME = f'{MODEL_NAME}-finetuned-snli'\n",
    "LOCAL_MODEL_CHECKPOINT = f'./models/{PROJECT_NAME}/checkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS  = [\"entailment\", \"neutral\", \"contradiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85a4f5031ed4457a1a6c66d89c3e779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-21d54e6470652178.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-b746e1998966e2f4.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-89fb34b79586ce05.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'labels'],\n",
       "        num_rows: 9824\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'labels'],\n",
       "        num_rows: 549367\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'labels'],\n",
       "        num_rows: 9842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('snli')\n",
    "dataset = dataset.filter(lambda example: example['label'] != -1) \n",
    "dataset = dataset.rename_column('label', 'labels')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1037, 2711, 2006, 1037, 3586, 14523, 2058, 1037, 3714, 2091, 13297, 1012, 102, 1037, 2711, 2003, 2731, 2010, 3586, 2005, 1037, 2971, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(HUB_MODEL_CHECKPOINT)\n",
    "\n",
    "example = dataset['train'][0]\n",
    "tokenizer(example['premise'], example['hypothesis'], return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-3e1d4c5a625bb5e4.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-15aa4b713d7ef0ac.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-5ec5b04d410c1bcb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "def tokenization(example):\n",
    "    return tokenizer(example['premise'], \n",
    "                     example['hypothesis'],\n",
    "                     padding='max_length',\n",
    "                     max_length=MAX_LENGTH, \n",
    "                     return_token_type_ids=True,\n",
    "                     return_attention_mask=True,\n",
    "                     truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenization, batched=True)\n",
    "\n",
    "for key in dataset.keys():\n",
    "    dataset[key].set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(dataset['train'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([1, 2]),\n",
       " 'input_ids': tensor([[  101,  1037,  2711,  2006,  1037,  3586, 14523,  2058,  1037,  3714,\n",
       "           2091, 13297,  1012,   102,  1037,  2711,  2003,  2731,  2010,  3586,\n",
       "           2005,  1037,  2971,  1012,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  1037,  2711,  2006,  1037,  3586, 14523,  2058,  1037,  3714,\n",
       "           2091, 13297,  1012,   102,  1037,  2711,  2003,  2012,  1037, 15736,\n",
       "           1010, 13063,  2019, 18168, 12260,  4674,  1012,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = dataset['train'][0:2]\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_trainable_params(model):\n",
    "    return np.sum(np.array([p.numel() for p in model.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, model_checkpoint, num_labels=3):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_checkpoint)\n",
    "        self.num_labels = num_labels\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, self.num_labels)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        features = {k: v for k, v in features.items() if k in ['input_ids', 'token_type_ids', 'attention_mask']}\n",
    "        embeddings = self.bert(**features).pooler_output ### CLS pooling\n",
    "        return self.classifier(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4356,  0.1097, -0.0216],\n",
       "        [ 0.4466,  0.0991, -0.0077]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClassifier(model_checkpoint=HUB_MODEL_CHECKPOINT)\n",
    "model(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of trainable params: 109M\n",
      "Actual number of trainable params: 109484547\n"
     ]
    }
   ],
   "source": [
    "FREEZE_ENCODER = False\n",
    "\n",
    "\n",
    "assert model.num_labels == NUM_LABELS, f'The number of labels should be {NUM_LABELS}'\n",
    "print(f'Original number of trainable params: {round(get_number_of_trainable_params(model)/1_000_000)}M')\n",
    "\n",
    "if FREEZE_ENCODER:\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith('classifier'):\n",
    "            param.requires_grad = False\n",
    "\n",
    "print(f'Actual number of trainable params: {get_number_of_trainable_params(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizer(model, lr, eps, warmup_steps, weight_decay, num_training_steps):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, eps=eps, correct_bias=False, weight_decay=weight_decay)\n",
    "    scheduler = get_scheduler('linear', optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps)\n",
    "#     scheduler = get_scheduler('constant', optimizer, num_warmup_steps=warmup_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def compute_metrics(predictions, labels):\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    correct = (predictions == labels).float()\n",
    "    accuracy = correct.mean()\n",
    "    return {'accuracy': accuracy, 'correct': correct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(accelerator, model, dataloader, optimizer, scheduler, loss_fn):\n",
    "    epoch_size = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(dataloader):        \n",
    "        optimizer.zero_grad() # clear gradients first\n",
    "        labels = batch['labels']\n",
    "        batch_size = labels.shape[0]\n",
    "        predictions = model(batch)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            metrics = compute_metrics(accelerator.gather(predictions), accelerator.gather(labels))\n",
    "            correct = metrics['correct'].cpu().numpy().sum()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_correct += correct\n",
    "            epoch_size += batch_size\n",
    "            \n",
    "    return {\n",
    "        'train_loss': round(epoch_loss/epoch_size, 5), \n",
    "        'train_accuracy': epoch_correct/epoch_size, \n",
    "        'learning_rate': scheduler.get_last_lr()[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(accelerator, model, dataloader, loss_fn):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_size = 0\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader):   \n",
    "        labels = batch['labels']\n",
    "        batch_size = labels.shape[0]\n",
    "        with torch.no_grad():\n",
    "            predictions = model(batch)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        metrics = compute_metrics(accelerator.gather(predictions), accelerator.gather(labels))\n",
    "        correct = metrics['correct'].cpu().numpy().sum()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += correct\n",
    "        epoch_size += batch_size\n",
    "    return {\n",
    "        'eval_loss': round(epoch_loss/epoch_size, 5), \n",
    "        'eval_accuracy': epoch_correct/epoch_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(accelerator, model, dataloader):\n",
    "    epoch_correct = 0\n",
    "    epoch_size = 0\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader):   \n",
    "        labels = batch['labels']\n",
    "        batch_size = labels.shape[0]\n",
    "        with torch.no_grad():\n",
    "            predictions = model(batch)\n",
    "        metrics = compute_metrics(accelerator.gather(predictions), accelerator.gather(labels))\n",
    "        correct = metrics['correct'].cpu().numpy().sum()\n",
    "        epoch_correct += correct\n",
    "        epoch_size += batch_size\n",
    "    return {\n",
    "        'test_accuracy': epoch_correct/epoch_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=3, verbose=False, delta=0.0, path=f'models/{PROJECT_NAME}/checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model, optimizer):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, optimizer)\n",
    "        elif score > self.best_score - self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, optimizer)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, optimizer):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        save_dir = self.path.split('checkpoint.pt')[0][:-1]\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': {'eval_loss': val_loss},\n",
    "        }, self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback = EarlyStoppingCallback(verbose=True, patience=3, delta=0.0001)\n",
    "# callback(0.02733, model, optimizer)\n",
    "# print(callback.best_score)\n",
    "# print(callback.counter)\n",
    "# callback.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(f'./models/{PROJECT_NAME}/checkpoint.pt')\n",
    "# print(checkpoint.keys())\n",
    "# checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective training batch size: 32\n",
      "Number of training steps per epoch: 2813\n",
      "Max number of epochs: 10\n",
      "Total training steps: 28130\n",
      "Warmup steps: 2813\n"
     ]
    }
   ],
   "source": [
    "FREEZE_ENCODER = False\n",
    "MIXED_PRECISION = 'fp16'\n",
    "TRAIN_SAMPLES = 90000\n",
    "EVAL_SAMPLES = 9000\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 16\n",
    "TRAIN_BATCH_SIZE = GRADIENT_ACCUMULATION_STEPS * PER_DEVICE_TRAIN_BATCH_SIZE\n",
    "print(f'Effective training batch size: {TRAIN_BATCH_SIZE}')\n",
    "EVAL_BATCH_SIZE = 90\n",
    "TRAIN_STEPS_PER_EPOCH = math.ceil(TRAIN_SAMPLES/TRAIN_BATCH_SIZE)\n",
    "print(f'Number of training steps per epoch: {TRAIN_STEPS_PER_EPOCH}')\n",
    "MAX_EPOCHS = 10\n",
    "print(f'Max number of epochs: {MAX_EPOCHS}')\n",
    "LR = 2e-5\n",
    "EPS = 1e-6\n",
    "WEIGHT_DECAY = 1e-4\n",
    "WARMUP_PERCENT = 0.1\n",
    "TOTAL_STEPS = MAX_EPOCHS * TRAIN_STEPS_PER_EPOCH\n",
    "print(f'Total training steps: {TOTAL_STEPS}')\n",
    "WARMUP_STEPS = int(TOTAL_STEPS*WARMUP_PERCENT)\n",
    "print(f'Warmup steps: {WARMUP_STEPS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_loop(seed=42, mixed_precision='fp16'):\n",
    "    set_seed(seed)\n",
    "    accelerator = Accelerator(mixed_precision=mixed_precision)\n",
    "\n",
    "    train_ds = dataset['train'].shuffle(seed=seed).select(range(TRAIN_SAMPLES))\n",
    "    eval_ds = dataset['validation'].shuffle(seed=seed).select(range(EVAL_SAMPLES))\n",
    "    train_dataloader = DataLoader(train_ds, num_workers=os.cpu_count(), batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    eval_dataloader = DataLoader(eval_ds, num_workers=os.cpu_count(), batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = BERTClassifier(model_checkpoint=HUB_MODEL_CHECKPOINT)\n",
    "    if FREEZE_ENCODER:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not name.startswith('classifier'):\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    optimizer, lr_scheduler = configure_optimizer(model, LR, EPS, WARMUP_STEPS, WEIGHT_DECAY, TOTAL_STEPS)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    early_stopping_callback = EarlyStoppingCallback(patience=3, delta=1e-5, verbose=True)\n",
    "\n",
    "    model, optimizer, train_dataloader, lr_scheduler, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, lr_scheduler, eval_dataloader\n",
    "    )\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        train_metrics = train_loop(accelerator, model, train_dataloader, optimizer, lr_scheduler, loss_fn)\n",
    "        eval_metrics = eval_loop(accelerator, model, eval_dataloader, loss_fn)\n",
    "        epoch_metrics = {**train_metrics, **eval_metrics}\n",
    "        accelerator.print(f\"epoch {epoch}: {epoch_metrics}\")\n",
    "        wandb.log(epoch_metrics)\n",
    "        early_stopping_callback(eval_metrics['eval_loss'], model, optimizer)\n",
    "        if early_stopping_callback.early_stop:\n",
    "            print(\"Early stopping at epoch:\", epoch)\n",
    "            break\n",
    "            \n",
    "    test_ds = dataset['test'].shuffle(seed=42).select(range(EVAL_SAMPLES))\n",
    "    test_dataloader = DataLoader(test_ds, num_workers=os.cpu_count(), batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "    test_metrics = test_loop(accelerator, model, eval_dataloader)\n",
    "    accelerator.print(f\"Test metrics: {test_metrics}\")\n",
    "    wandb.log(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/ml-examples/natural-language-processing/nli/wandb/run-20221004_014454-29si1gpm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/thierry-wendling-research/bert-base-uncased-finetuned-snli/runs/29si1gpm\" target=\"_blank\">happy-brook-15</a></strong> to <a href=\"https://wandb.ai/thierry-wendling-research/bert-base-uncased-finetuned-snli\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-1c0f125df70dcab0.arrow\n",
      "Loading cached shuffled indices for dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-a88183f3ca55bbac.arrow\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "100%|██████████| 2813/2813 [10:52<00:00,  4.31it/s]\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'train_loss': 0.01866, 'train_accuracy': 0.7485444444444445, 'learning_rate': 1.9985780305723426e-05, 'eval_loss': 0.00438, 'eval_accuracy': 0.8541111111111112}\n",
      "Validation loss decreased (inf --> 0.004380).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [10:59<00:00,  4.27it/s]\n",
      "100%|██████████| 100/100 [00:22<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: {'train_loss': 0.01205, 'train_accuracy': 0.8550444444444445, 'learning_rate': 1.7780147726823876e-05, 'eval_loss': 0.00401, 'eval_accuracy': 0.8681111111111111}\n",
      "Validation loss decreased (0.004380 --> 0.004010).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [11:00<00:00,  4.26it/s]\n",
      "100%|██████████| 100/100 [00:22<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: {'train_loss': 0.00819, 'train_accuracy': 0.9061444444444444, 'learning_rate': 1.555871548761702e-05, 'eval_loss': 0.00403, 'eval_accuracy': 0.8717777777777778}\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [11:04<00:00,  4.23it/s]\n",
      "100%|██████████| 100/100 [00:21<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: {'train_loss': 0.00546, 'train_accuracy': 0.9406111111111111, 'learning_rate': 1.3338073231425525e-05, 'eval_loss': 0.00493, 'eval_accuracy': 0.8733333333333333}\n",
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [11:00<00:00,  4.26it/s]\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.31it/s]\n",
      "Loading cached shuffled indices for dataset at /home/ec2-user/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-7bb9322cbe3cec9f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: {'train_loss': 0.00367, 'train_accuracy': 0.9609222222222222, 'learning_rate': 1.1117430975234033e-05, 'eval_loss': 0.00554, 'eval_accuracy': 0.8703333333333333}\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping at epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'test_accuracy': 0.8703333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME)\n",
    "\n",
    "epoch_loop(seed=42, mixed_precision=MIXED_PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec2a66610d4718be4d105912098227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>▁▆▇█▇</td></tr><tr><td>eval_loss</td><td>▃▁▁▅█</td></tr><tr><td>learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>0.87033</td></tr><tr><td>eval_loss</td><td>0.00554</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>test_accuracy</td><td>0.87033</td></tr><tr><td>train_accuracy</td><td>0.96092</td></tr><tr><td>train_loss</td><td>0.00367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">happy-brook-15</strong>: <a href=\"https://wandb.ai/thierry-wendling-research/bert-base-uncased-finetuned-snli/runs/29si1gpm\" target=\"_blank\">https://wandb.ai/thierry-wendling-research/bert-base-uncased-finetuned-snli/runs/29si1gpm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221004_014454-29si1gpm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test finetuned model on examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_state_dict', 'optimizer_state_dict', 'loss'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(LOCAL_MODEL_CHECKPOINT)\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClassifier(model_checkpoint=HUB_MODEL_CHECKPOINT)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_example(example):\n",
    "    return tokenizer(example['premise'], \n",
    "                     example['hypothesis'],\n",
    "                     padding='max_length',\n",
    "                     max_length=MAX_LENGTH, \n",
    "                     return_tensors='pt',\n",
    "                     return_token_type_ids=True,\n",
    "                     return_attention_mask=True,\n",
    "                     truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(premise, hypothesis):\n",
    "    example = {\n",
    "        \"premise\": premise,\n",
    "        \"hypothesis\": hypothesis,\n",
    "    }\n",
    "    encoded = encode_example(example)\n",
    "    label_idx = model(encoded).argmax(dim=-1).item()\n",
    "    print(LABELS[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I go to the office with my personal car.', 'I take the bus to reach the office')\n",
      "contradiction\n",
      "('He is techy', 'He has good knowledge of tech')\n",
      "entailment\n",
      "('I use my personal car to go to work', 'I usually share a taxi to reach the office')\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "pairs = [ \n",
    "    ('I go to the office with my personal car.', 'I take the bus to reach the office'),\n",
    "    ('He is techy', 'He has good knowledge of tech'),\n",
    "    ('I use my personal car to go to work', 'I usually share a taxi to reach the office')\n",
    "]\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    predict_class(pair[0], pair[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (Local)",
   "language": "python",
   "name": "local-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5517fee858da220e354b0e7f8c879a17a674f17dc1b2bfda8d8bbe6e302f27df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
